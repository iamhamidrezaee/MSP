{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Microsoft Stocks Project**\n",
    "\n",
    "**The purpose** of this model is to find patterns in Microsoft's stock price having the past stocks data.\n",
    "\n",
    "**The goal** of this model is to predict the Microsoft's stock price based on the data at hand.\n",
    "\n",
    "*This model's components are labeled with the respective **PACE stage: Plan, Analyze, Construct, Execute**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PACE: Plan**\n",
    "\n",
    "1. What are we going to accomplish with this model?\n",
    "\n",
    "    >*Predict the price of microsoft stocks as accurately as possible.*\n",
    "\n",
    "2. Is the data reliable? \n",
    "\n",
    "    >*The dataset has Microsoft's stock data from the year 1986 to 2023, which gives us a sufficient amount of data to build the model. In addition, the data has all the factors necessary to predict the stock price, which makes the data reliable for our model.*\n",
    "\n",
    "3. What resources will we use as you complete this stage?\n",
    "\n",
    "    >*In the Plan stage, the main resources that we use are the dataset and the imported packages (described below) for building the model and data inspection.*\n",
    "\n",
    "4. Does this model have ethical implications?\n",
    "\n",
    "    >*If this model makes inaccurate predictions about the stock prices, it will have a negative financial impact on the clients who want to have an accurate prediction of the stock price. In that case, the inaccuracy should be immedietely evaluated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Imports and data loading\n",
    "\n",
    "At first, we import packages and libraries needed to build the XGBoost model and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import XGBoost Regressor model package\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Import packages for data visualization \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import packages for data modeling\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# Import packages for metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Import packages to handle missing data\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# This lets us see all the columns, preventing Jupyter from redacting them.\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in the dataset as `df0` and inspect the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/15/2023</td>\n",
       "      <td>309.46</td>\n",
       "      <td>309.10</td>\n",
       "      <td>309.90</td>\n",
       "      <td>307.59</td>\n",
       "      <td>16290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/12/2023</td>\n",
       "      <td>308.97</td>\n",
       "      <td>310.55</td>\n",
       "      <td>310.65</td>\n",
       "      <td>306.60</td>\n",
       "      <td>19770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/11/2023</td>\n",
       "      <td>310.11</td>\n",
       "      <td>310.10</td>\n",
       "      <td>311.12</td>\n",
       "      <td>306.26</td>\n",
       "      <td>31680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05/10/2023</td>\n",
       "      <td>312.31</td>\n",
       "      <td>308.62</td>\n",
       "      <td>313.00</td>\n",
       "      <td>307.67</td>\n",
       "      <td>30080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/09/2023</td>\n",
       "      <td>307.00</td>\n",
       "      <td>308.00</td>\n",
       "      <td>310.04</td>\n",
       "      <td>306.31</td>\n",
       "      <td>21340000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Price    Open    High     Low    Volume\n",
       "0  05/15/2023  309.46  309.10  309.90  307.59  16290000\n",
       "1  05/12/2023  308.97  310.55  310.65  306.60  19770000\n",
       "2  05/11/2023  310.11  310.10  311.12  306.26  31680000\n",
       "3  05/10/2023  312.31  308.62  313.00  307.67  30080000\n",
       "4  05/09/2023  307.00  308.00  310.04  306.31  21340000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "df0 = pd.read_csv('MicrosoftStocks.csv')\n",
    "\n",
    "# Inspect the first five rows\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PACE: Analyze**\n",
    "\n",
    "1. Does the plan need revising?\n",
    "\n",
    "> *Our resources are sufficient for building the model and the based on our choices of the model and other components such as the metrics, tools for handling data, and visualizing data, and engineering the data, the plan goes well and does not need significant fundamental revision.*\n",
    "\n",
    "2. Does the data break the assumptions of the model? Is that ok, or unacceptable?\n",
    "\n",
    "> *For predicting the stock price, the data we need is the components necessary for stock price prediction, and our dataset has it which includes the stocks end price, low and high, volume and the date. The data does not break the assumptions of the model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Feature Engineering\n",
    "\n",
    "At this stage, we are going to engineer features and, from the existing features, new features to use in the modeling and improvement of the model performance and prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a copy of `df0` to preserve the original datafram and call the copy `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe\n",
    "df = df0.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `info()` on the new dataframe so the columns in the datafram can be easily referenced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of             Date   Price    Open    High     Low     Volume\n",
       "0     05/15/2023  309.46  309.10  309.90  307.59   16290000\n",
       "1     05/12/2023  308.97  310.55  310.65  306.60   19770000\n",
       "2     05/11/2023  310.11  310.10  311.12  306.26   31680000\n",
       "3     05/10/2023  312.31  308.62  313.00  307.67   30080000\n",
       "4     05/09/2023  307.00  308.00  310.04  306.31   21340000\n",
       "...          ...     ...     ...     ...     ...        ...\n",
       "9364  03/20/1986    0.10    0.10    0.10    0.09   58440000\n",
       "9365  03/19/1986    0.10    0.10    0.10    0.10   47890000\n",
       "9366  03/18/1986    0.10    0.10    0.10    0.10   66470000\n",
       "9367  03/17/1986    0.10    0.10    0.10    0.10  133169999\n",
       "9368  03/14/1986    0.10    0.10    0.10    0.10  308160000\n",
       "\n",
       "[9369 rows x 6 columns]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the info about our dataframe\n",
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Date Modification`\n",
    "\n",
    "The date column in our original dataframe has the date in object format. We need to modify it by calling the `to_datetime()` on our `Date` column to convert it into Pandas date format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the 'Date' in the dataframe\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we extract the `year`, `month`, `dayofweek`, and `quarter` from the `Date` as it will help us in finding the seasonal patterns in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for year\n",
    "df['year'] = df['Date'].dt.year\n",
    "\n",
    "# Create a new column for month\n",
    "df['month'] = df['Date'].dt.month\n",
    "\n",
    "# Create a new column for day of week\n",
    "df['day'] = df['Date'].dt.dayofweek\n",
    "\n",
    "# Create a new column for the quarter\n",
    "df['quarter'] = df['Date'].dt.quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `daily_range`\n",
    "\n",
    "Creating a new feature called `daily_range` that represents the difference between the highest and the lowest trading prices of stock in a day. \n",
    "\n",
    "*Note: In substracting the values of the two columns `High` and `Low`,  Pandas use vectorization in calculating the values for the `daily_range`, utilizing parallel hardware of the GPU.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature 'daily_range' (high - low)\n",
    "df['daily_range'] = df['High'] - df['Low']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `volume_change`\n",
    "\n",
    "Creating a feature called `volume_change` that represents the percentage change in the volume. It is a measure of how much the volume changed from one day to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature `volume_change`\n",
    "df['volume_change'] = df['Volume'].pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `price_increase`\n",
    "\n",
    "Creating a new binary feature called `price_increase` that represents whether or not the price increased since the day before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature `price_increase`\n",
    "df['price_increase'] = (df['Price'] > df['Price'].shift(1)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Calculating the MACD`\n",
    "\n",
    "MACD (Moving Average Convergence Divergence) is an indicator in stock markte analysis to identify trends and momentum in a stock's price. \n",
    "\n",
    "It provides us with:\n",
    "\n",
    "* The Exponential Moving Average (EMA) in short-term `shortEMA`\n",
    "\n",
    "* The Exponential Moving Average (EMA) in long-term `longEMA`\n",
    "\n",
    "* The `MACD` value that helps us identify the convergence or divergence of the short and long-term trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_macd(df, short_window=12, long_window=26, signal_window=9):\n",
    "    \"\"\"\n",
    "    Calculate the Moving Average Convergence Divergence (MACD) indicator for a given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the stock price data. It should have a 'Date' column and a 'Price' column.\n",
    "        short_window (int): Number of days for the short-term moving average (default is 12).\n",
    "        long_window (int): Number of days for the long-term moving average (default is 26).\n",
    "        signal_window (int): Number of days for the signal line moving average (default is 9).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame containing the MACD, signal line, and MACD histogram.\n",
    "    \"\"\"\n",
    "    df['shortEMA'] = df['Price'].ewm(span=short_window, adjust=False).mean()\n",
    "\n",
    "    df['longEMA'] = df['Price'].ewm(span=long_window, adjust=False).mean()\n",
    "\n",
    "    df['MACD'] = df['shortEMA'] - df['longEMA']\n",
    "\n",
    "    df['signalLine'] = df['MACD'].ewm(span=signal_window, adjust=False).mean()\n",
    "\n",
    "    df['MACD_histogram'] = df['MACD'] - df['signalLine']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we concatenate the dataframe we returned from `calculate_macd` function with the copy of our original dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>quarter</th>\n",
       "      <th>daily_range</th>\n",
       "      <th>volume_change</th>\n",
       "      <th>price_increase</th>\n",
       "      <th>shortEMA</th>\n",
       "      <th>longEMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>signalLine</th>\n",
       "      <th>MACD_histogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-15</td>\n",
       "      <td>309.46</td>\n",
       "      <td>309.10</td>\n",
       "      <td>309.90</td>\n",
       "      <td>307.59</td>\n",
       "      <td>16290000</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>309.460000</td>\n",
       "      <td>309.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>308.97</td>\n",
       "      <td>310.55</td>\n",
       "      <td>310.65</td>\n",
       "      <td>306.60</td>\n",
       "      <td>19770000</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.213628</td>\n",
       "      <td>0</td>\n",
       "      <td>309.384615</td>\n",
       "      <td>309.423704</td>\n",
       "      <td>-0.039088</td>\n",
       "      <td>-0.007818</td>\n",
       "      <td>-0.031271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>310.11</td>\n",
       "      <td>310.10</td>\n",
       "      <td>311.12</td>\n",
       "      <td>306.26</td>\n",
       "      <td>31680000</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.86</td>\n",
       "      <td>0.602428</td>\n",
       "      <td>1</td>\n",
       "      <td>309.496213</td>\n",
       "      <td>309.474540</td>\n",
       "      <td>0.021673</td>\n",
       "      <td>-0.001920</td>\n",
       "      <td>0.023592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>312.31</td>\n",
       "      <td>308.62</td>\n",
       "      <td>313.00</td>\n",
       "      <td>307.67</td>\n",
       "      <td>30080000</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.33</td>\n",
       "      <td>-0.050505</td>\n",
       "      <td>1</td>\n",
       "      <td>309.929103</td>\n",
       "      <td>309.684575</td>\n",
       "      <td>0.244529</td>\n",
       "      <td>0.047370</td>\n",
       "      <td>0.197159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>307.00</td>\n",
       "      <td>308.00</td>\n",
       "      <td>310.04</td>\n",
       "      <td>306.31</td>\n",
       "      <td>21340000</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.73</td>\n",
       "      <td>-0.290559</td>\n",
       "      <td>0</td>\n",
       "      <td>309.478472</td>\n",
       "      <td>309.485717</td>\n",
       "      <td>-0.007245</td>\n",
       "      <td>0.036447</td>\n",
       "      <td>-0.043692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Price    Open    High     Low    Volume  year  month  day  \\\n",
       "0 2023-05-15  309.46  309.10  309.90  307.59  16290000  2023      5    0   \n",
       "1 2023-05-12  308.97  310.55  310.65  306.60  19770000  2023      5    4   \n",
       "2 2023-05-11  310.11  310.10  311.12  306.26  31680000  2023      5    3   \n",
       "3 2023-05-10  312.31  308.62  313.00  307.67  30080000  2023      5    2   \n",
       "4 2023-05-09  307.00  308.00  310.04  306.31  21340000  2023      5    1   \n",
       "\n",
       "   quarter  daily_range  volume_change  price_increase    shortEMA  \\\n",
       "0        2         2.31            NaN               0  309.460000   \n",
       "1        2         4.05       0.213628               0  309.384615   \n",
       "2        2         4.86       0.602428               1  309.496213   \n",
       "3        2         5.33      -0.050505               1  309.929103   \n",
       "4        2         3.73      -0.290559               0  309.478472   \n",
       "\n",
       "      longEMA      MACD  signalLine  MACD_histogram  \n",
       "0  309.460000  0.000000    0.000000        0.000000  \n",
       "1  309.423704 -0.039088   -0.007818       -0.031271  \n",
       "2  309.474540  0.021673   -0.001920        0.023592  \n",
       "3  309.684575  0.244529    0.047370        0.197159  \n",
       "4  309.485717 -0.007245    0.036447       -0.043692  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the dataframes\n",
    "df = pd.concat([df, calculate_macd(df)], axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Handling Missing values\n",
    "\n",
    "In the above dataset, we can see that the new features are successfully added, though we have `NaN` or missing values. We use the method `isnull()` and `sum()` to check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN values: 2\n"
     ]
    }
   ],
   "source": [
    "# Count the numebr of NaN values in the dataset\n",
    "nan_count = df.isnull().sum().sum()\n",
    "\n",
    "# Print the number of NaN values. \n",
    "print(\"Total NaN values:\", nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 8 `NaN` values in our dataset, and missing values adversly affect the model's performance. That is why we are going to handle missing values using scikit-learn's imputer `IterativeImputer()`.\n",
    "\n",
    "An imputer treats missing values as it's target variable, uses a linear regression model to predict the missing value based on the other features, and updates the missing value with the predicted value. \n",
    "\n",
    "*Note: XGBoost model can handle the missing values itself, but it is a crucial step in developing the model to ensure the missing values are handled properly to avoid any negative impact on the model performance. Although iterative imputation is a computationally intensive method, it provides better imputation accuracy, and since it alligns with the ethical consideration of our model -- avoiding negative financial impact to the clients -- we will utilize that.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the columns with missing values into a list\n",
    "columns_with_missing_values = df.columns[df.isnull().any()].tolist()\n",
    "\n",
    "# Initialize the imputer\n",
    "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "\n",
    "# Fit the columns into the imputer\n",
    "imputer.fit(df[columns_with_missing_values])\n",
    "\n",
    "# Impute missing values in specific columns\n",
    "imputed_data = imputer.fit_transform(df[columns_with_missing_values])\n",
    "\n",
    "# Update the datafram with the imputed values\n",
    "df[columns_with_missing_values] = imputed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we handled the missing values, we should check and make sure there are no more missing values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "# Count the numebr of NaN values in the dataset\n",
    "nan_count = df.isnull().sum().sum()\n",
    "\n",
    "# Print the number of NaN values. \n",
    "print(\"Total NaN values:\", nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PACE: Construct**\n",
    "\n",
    "1. Do we notice anything odd? Is it a problem? Can it be fixed? If so, how?\n",
    "\n",
    "> *At this stage, there has not been anything odd or problematic. The only thing that **could've** resulted in something problematic was the missing data that we handled it, and everything else is ready.*\n",
    "\n",
    "2. Can you improve it? Is there anything you would change about the model?\n",
    "\n",
    "> *We do not see anything particular that needs to be changed at this stage, though we are flixable and aware of the model's performance and if, by any chance, it needs any a change, it will be brought with significant caution and awareness so that the change does not break any other part of the model.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. Modeling workflow\n",
    "\n",
    "At this stage, our data is ready to be splitted into training, validating, and testing sets. There are two steps to be taken:\n",
    "\n",
    "1. We are going to take the common 60/20/20 approach for splitting the data: \n",
    "- Training 60%\n",
    "- Validation 20%\n",
    "- Testing 20%\n",
    "\n",
    "\n",
    "2. We are going to fit the model and tune hyperparameters on the training sets to:\n",
    "- Avoiding overfitting or underfitting in the model\n",
    "- Having a robust model, less sensitive to small changes in the data\n",
    "- Hava a more interpretable and understandable model \n",
    "\n",
    "3. Perform cross-validation to: \n",
    "\n",
    "- Make sure we further reduce the risk of overfitting \n",
    "- Gain more confidence in models performance\n",
    "    \n",
    "\n",
    "4. Test the data to:\n",
    "\n",
    "- See how well it performs on unseen dataset\n",
    "- Simulate a real-world scenario\n",
    "- Get a sense of model's generalization error and how well \n",
    "    it performs on new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5. Splitting the data\n",
    "\n",
    "Now that we don't have any missing values in our dataset, it's time to isolate our `X` and `y` variables and specific columns for them. After isolating them, we check to make sure we have the right features for each of them.\n",
    "\n",
    "* We already extracted the necessary information from the `Date` column, so we are dropping it from our `X` variable since it does not contribute much to the model prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* We are dropping the `Price` from our `X` variable because it is what we are trying to predict (our `y` variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>quarter</th>\n",
       "      <th>daily_range</th>\n",
       "      <th>volume_change</th>\n",
       "      <th>price_increase</th>\n",
       "      <th>shortEMA</th>\n",
       "      <th>longEMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>signalLine</th>\n",
       "      <th>MACD_histogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>309.10</td>\n",
       "      <td>309.90</td>\n",
       "      <td>307.59</td>\n",
       "      <td>16290000</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.085302</td>\n",
       "      <td>0</td>\n",
       "      <td>309.460000</td>\n",
       "      <td>309.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>310.55</td>\n",
       "      <td>310.65</td>\n",
       "      <td>306.60</td>\n",
       "      <td>19770000</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.213628</td>\n",
       "      <td>0</td>\n",
       "      <td>309.384615</td>\n",
       "      <td>309.423704</td>\n",
       "      <td>-0.039088</td>\n",
       "      <td>-0.007818</td>\n",
       "      <td>-0.031271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310.10</td>\n",
       "      <td>311.12</td>\n",
       "      <td>306.26</td>\n",
       "      <td>31680000</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.86</td>\n",
       "      <td>0.602428</td>\n",
       "      <td>1</td>\n",
       "      <td>309.496213</td>\n",
       "      <td>309.474540</td>\n",
       "      <td>0.021673</td>\n",
       "      <td>-0.001920</td>\n",
       "      <td>0.023592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>308.62</td>\n",
       "      <td>313.00</td>\n",
       "      <td>307.67</td>\n",
       "      <td>30080000</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.33</td>\n",
       "      <td>-0.050505</td>\n",
       "      <td>1</td>\n",
       "      <td>309.929103</td>\n",
       "      <td>309.684575</td>\n",
       "      <td>0.244529</td>\n",
       "      <td>0.047370</td>\n",
       "      <td>0.197159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>308.00</td>\n",
       "      <td>310.04</td>\n",
       "      <td>306.31</td>\n",
       "      <td>21340000</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.73</td>\n",
       "      <td>-0.290559</td>\n",
       "      <td>0</td>\n",
       "      <td>309.478472</td>\n",
       "      <td>309.485717</td>\n",
       "      <td>-0.007245</td>\n",
       "      <td>0.036447</td>\n",
       "      <td>-0.043692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open    High     Low    Volume  year  month  day  quarter  daily_range  \\\n",
       "0  309.10  309.90  307.59  16290000  2023      5    0        2         2.31   \n",
       "1  310.55  310.65  306.60  19770000  2023      5    4        2         4.05   \n",
       "2  310.10  311.12  306.26  31680000  2023      5    3        2         4.86   \n",
       "3  308.62  313.00  307.67  30080000  2023      5    2        2         5.33   \n",
       "4  308.00  310.04  306.31  21340000  2023      5    1        2         3.73   \n",
       "\n",
       "   volume_change  price_increase    shortEMA     longEMA      MACD  \\\n",
       "0       0.085302               0  309.460000  309.460000  0.000000   \n",
       "1       0.213628               0  309.384615  309.423704 -0.039088   \n",
       "2       0.602428               1  309.496213  309.474540  0.021673   \n",
       "3      -0.050505               1  309.929103  309.684575  0.244529   \n",
       "4      -0.290559               0  309.478472  309.485717 -0.007245   \n",
       "\n",
       "   signalLine  MACD_histogram  \n",
       "0    0.000000        0.000000  \n",
       "1   -0.007818       -0.031271  \n",
       "2   -0.001920        0.023592  \n",
       "3    0.047370        0.197159  \n",
       "4    0.036447       -0.043692  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate X variable\n",
    "X = df.drop(columns = ['Price', 'Date'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Assign the `Price` as our `y` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    309.46\n",
       "1    308.97\n",
       "2    310.11\n",
       "3    312.31\n",
       "4    307.00\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate the y variable\n",
    "y = df['Price']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data as planned on our **Construct** stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, \n",
    "                                              test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the train sets into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, \n",
    "                                                  test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having the partitions, it's time to verify the number of samples in each partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18738\n"
     ]
    }
   ],
   "source": [
    "# Total number of samples\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11242\n",
      "3748\n",
      "3748\n"
     ]
    }
   ],
   "source": [
    "# Verify the partitions\n",
    "for x in [X_train, X_val, X_test]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 74952 samples that we have, 60% of it is ~44971, and 20% of it is ~14990, so the number of samples in each partition perfectly aligns with our expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6. Modeling\n",
    "\n",
    "**XGBoost**\n",
    "\n",
    "We begin with Grid Search Cross-Validation (`GridSeachCV`) to tune the XGBoost model.\n",
    "\n",
    "1. We instantiate the XGBoost regressor `xgb` and set the random state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "xgb = XGBRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Then, we create the dictionary `cv_params` of the following hyperparameters and their corresponding values to tune. \n",
    "\n",
    "* `max_depth`\n",
    "* `min_child_weight`\n",
    "* `learning_rate`\n",
    "* `n_estimators`\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dictionary for hyperparameters\n",
    "cv_params = {'max_depth': [6, 12],\n",
    "             'min_child_weight': [3, 5],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             'n_estimators': [300]\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a dictionary `scoring` of the following scoring metrics for GridSearch to capture:\n",
    "\n",
    "* `neg_mean_squared_error`\n",
    "* `r2`\n",
    "* `neg_mean_absolute_error`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring dictionary\n",
    "scoring = {'neg_mean_squared_error', \n",
    "           'r2', \n",
    "           'neg_mean_absolute_error',\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. Lastly, we instantiate the `GridSearchCV` object `xgb_cv` and pass to it the above arguements we made:\n",
    "\n",
    "* estimator=`xgb`\n",
    "* param_grid=`cv_params`\n",
    "* scoring=`scoring`\n",
    "* cv=`5` (number of cross validtion folds)\n",
    "* refit=`neg_mean_squared_error` (the metric we want to evaluate the performance of different hyperparamter combinations)\n",
    "\n",
    "*Note: We chose `neg_mean_squared_error` as the metric we want to evaluate the model performance because Mean Squared Error measures the squared difference between our predicted values and the actual values, or in other words, how far our prediction is from the true values. The reason we chose the **Negative** Mean Squared Error specifically is that when it's maximized, the actual mean squared error will be minimized, which aligns well with scikit-learn's scoring functions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch Instantiation\n",
    "xgb_cv = GridSearchCV(xgb, cv_params, scoring=scoring, cv=5, refit='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model to the training data.\n",
    "\n",
    "*Note: This cell will utilize a higher percentage of CPU. It is recommended that you monitor your CPU performance and make sure the performance doesn't result in excessive overheat of the computer since continuous high CPU usage and overheat results in bad perfomance, data loss, or system instability. You can monitor your CPU performance by opening `Task Manager` on Windows or  `Activity Monitor` on IOS.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11min 48s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=42, ...),\n",
       "             param_grid={'learning_rate': [0.01, 0.1], 'max_depth': [6, 12],\n",
       "                         'min_child_weight': [3, 5], 'n_estimators': [300]},\n",
       "             refit='neg_mean_squared_error',\n",
       "             scoring={'neg_mean_absolute_error', 'neg_mean_squared_error',\n",
       "                      'r2'})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the model to the training data\n",
    "xgb_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we fitted the model, it is time to get its components. First, let's check the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4088841633537574"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best score\n",
    "xgb_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 12,\n",
       " 'min_child_weight': 5,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best parameteres\n",
    "xgb_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7. Getting the Scores\n",
    "\n",
    "Visualizing the scores is an important step in our model development. With a clear understanding of the model's scores, we can have an idea of how well it's performing, and whether it needs modifications or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a clear visualization of the scores, we are going to make the `make_results()` function. This function accepts three arguments and outputs all of the scores of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model_name (string): what you want the model to be called in the output table\n",
    "        model_object: a fit GridSearchCV object\n",
    "        metric (string): 'neg_mean_squared_error', 'r2', or 'neg_mean_absolute_error'\n",
    "\n",
    "        Returns a pandas df with the 'neg_mean_squared_error','r2', and 'neg_mean_absolute_error'\n",
    "        for the model with the best mean 'metric' score across all validation folds\n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps inputs metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {'mse': 'mean_test_neg_mean_squared_error',  # Use 'mean_test_' prefix for GridSearchCV's metrics\n",
    "                   'r2': 'mean_test_r2',\n",
    "                   'mae': 'mean_test_neg_mean_absolute_error'\n",
    "                    }\n",
    "    \n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract MSE, R2, MAE from that row\n",
    "    mse = best_estimator_results.mean_test_neg_mean_squared_error\n",
    "    r2 = best_estimator_results.mean_test_r2\n",
    "    mae = best_estimator_results.mean_test_neg_mean_absolute_error\n",
    "\n",
    "    # Create a table of results\n",
    "    table = pd.DataFrame({'model' : [model_name],\n",
    "                          'MSE' : [mse],\n",
    "                          'R2' : [r2],\n",
    "                          'MAE' : [mae]\n",
    "                          })\n",
    "    \n",
    "    return table\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the function is ready to make a table out of our scores, we will pass the `GridSearch` object to the `make_results()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB CV</td>\n",
       "      <td>-0.408884</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>-0.190525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model       MSE        R2       MAE\n",
       "0  XGB CV -0.408884  0.999917 -0.190525"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the results table with our model scores\n",
    "xgb_cv_results = make_results('XGB CV', xgb_cv, 'mse')\n",
    "xgb_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see a table of the scores. Now it's time to define the function `get_test_scores` to generate a table of scores from the **prediction** and **validation** scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_scores(model_name:str, preds, y_test_data):\n",
    "    '''\n",
    "    Generate a table of test scores\n",
    "\n",
    "    In:\n",
    "        model_name (string): how the model will be named in the output table\n",
    "        preds: numpy array of test predictions\n",
    "        y_test_data: numpy array of y_test data\n",
    "\n",
    "    Out:\n",
    "        table: a pandas df of MAE, MSE, and R2 scores for the model\n",
    "    '''\n",
    "    mse = mean_squared_error(y_test_data, preds)\n",
    "    mae = mean_absolute_error(y_test_data, preds)\n",
    "    r2score = r2_score(y_test_data, preds)\n",
    "\n",
    "    table = pd.DataFrame({'model' : [model_name],\n",
    "                          'MSE':[mse],\n",
    "                          'MAE':[mae],\n",
    "                          'R2':[r2score]\n",
    "                          })\n",
    "    \n",
    "    return table\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we take the model's scores on the validation data and add it to our results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB CV</td>\n",
       "      <td>-0.408884</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>-0.190525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB Val</td>\n",
       "      <td>0.271265</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.143244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model       MSE        R2       MAE\n",
       "0   XGB CV -0.408884  0.999917 -0.190525\n",
       "0  XGB Val  0.271265  0.999943  0.143244"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use XGBoost model to predit on validation data\n",
    "xgb_val_preds = xgb_cv.best_estimator_.predict(X_val)\n",
    "\n",
    "# Get the validation test scores for XGBoost model\n",
    "xgb_val_scores = get_test_scores('XGB Val', xgb_val_preds, y_val)\n",
    "\n",
    "# Concatenate the model scores and the validation scores tables\n",
    "results = pd.concat([xgb_cv_results, xgb_val_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have a table that has both scores of our model and the scores on the validation data. So far, we have an idea of the model's performance, which, based on the values of the MSE, R2, and MAE, it is performing pretty well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PACE: Execute**\n",
    "\n",
    "1. Does my model make sense? Are my final results acceptable?\n",
    "\n",
    "> *The model makes sense based on the utilization of the features and the scores on the validation and test data. Besides, the model is explainable and understandable, which adds to our confidence that the results and acceptable.*\n",
    "\n",
    "2. Do we think our model could be improved? Why or why not? How?\n",
    "\n",
    "> *Taking in a broader sense, if we develop a stacking that includes XGBoost, Random Forest, and Support Vector Regression (base learners) and train them, and then use the base learners' predictions to train a meta-model to combine the predictions of the base learners and make a final prediction, there is a possiblity of improvement since we will have the prediction of three powerful models. However, the imporvement cannot be guaranteed in advance as we will need to analyze the performance of the models and see whether the predictions are accurate and reliable or not.*   \n",
    "\n",
    "3. Finally, what business/organizational recommendations can we propose based on the models built?\n",
    "\n",
    "> *We recommend an investment on a software engieering and machine learning developing team for a comprehensive research on the application techniques that will significantly accelerate the models execution, which can provide the responses not only accurately but in exceptionally low computational intensity.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As a final step, we are going to use the model to predict on the test data. This steps shows how the model will perform on completely new, unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB CV</td>\n",
       "      <td>-0.408884</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>-0.190525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB Val</td>\n",
       "      <td>0.271265</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.143244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB Test</td>\n",
       "      <td>0.217163</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.137317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model       MSE        R2       MAE\n",
       "0    XGB CV -0.408884  0.999917 -0.190525\n",
       "0   XGB Val  0.271265  0.999943  0.143244\n",
       "0  XGB Test  0.217163  0.999956  0.137317"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use our XGBoost model to predict on test data\n",
    "xgb_test_preds = xgb_cv.best_estimator_.predict(X_test)\n",
    "\n",
    "# Get test scores for our XGBoost model\n",
    "xgb_test_scores = get_test_scores('XGB Test', xgb_test_preds, y_test)\n",
    "\n",
    "# Append to the results table\n",
    "results = pd.concat([results, xgb_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs exceptionally well; the `r2` score is very close to 1, and the MSE and MAE values are decently low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8. Feature Importance\n",
    "\n",
    "As the last task of the development of this model, we are going to inspect the most important features of our model. We do so with visualizing the the feature importance based on `weight` and `gain` metrics. \n",
    "\n",
    "`weight` tells us how many times a feature appeared in the trees of the model, which means features with higher weights are used more in the training of the model. Note that `weight` does not take into account how much a feature contributed in reducing the model's loss.\n",
    "\n",
    "`gain`, on the other hand, tells us how much a feature contributed in reducing the model's loss. Features with higher gains are more informative and lead to larger reductions in the model's loss during the training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the `weight` and `gain` scores, we first have to get the booster `get_booster()` of our model's `best_estimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the booster of the model's best estimator\n",
    "booster = xgb_cv.best_estimator_.get_booster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the booster, we proceed to displaying the `weight` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAz7klEQVR4nO3deZxcVZn/8c+XAAGBsEhASAJBZF9kiYA/FBdUUNTggsIoREUzIuMyOiooM4CK4joOzAiDIoRNDIsCKjuyaSCGNaxDBIQAQkSWgGyB5/fHOUVuV6rT1V2nqm8n3/fr1a+uOlV1nttd3fXce1ZFBGZmZnWzzHAfgJmZWStOUGZmVktOUGZmVktOUGZmVktOUGZmVktOUGZmVktOUGY2KJLGSrpT0gqF632jpDvbfO6bJc0dZP0zJW0xtKOz4eAEZYMi6V5Jz0h6qvK1boE631bqGNuId5ikU3oVb3EkfUzS1cN9HIN0EHBCRDwraR9Jt1UflHRxP2UHLa7SiLgqIjYpcYCSTpT0rabiHwDfKFG/9YYTlA3FeyJi5crXg8N5MJKWHc74QzUSj1vSaGAK0EjwVwCbSRqbH18WeC3wiqay1wNX9v6I+zgXeIukdYb5OKxNTlBWhKRVJR0v6SFJD0j6lqRR+bENJV0m6VFJf5N0qqTV8mMnA+sB5+Wrsa+0ar6pXmXlK6AzJZ0i6UngY4uL38axh6TPSLpL0nxJ38zHPEPSk5KmS1o+P/fNkuZK+lr+We6V9JGm38NJkuZJ+oukQyQtkx/7mKQ/SPpPSX8HfgkcC7w+/+yP5+ftIemGHPt+SYdV6p+Yj3eKpPvyMXy98viofGx/zj/LdZIm5Mc2zVcyf89NdB+qvO5dkm7Lr3lA0r/18+vaEXg8IuYC5JOTu4Fd8uPbAbeSEle1bBlglqTRkn6Qj/1hScdKWrH6u60c03b59zBf0hmSftl8VSTpS5Ieye/7x3PZVOAjwFfy7/W8fKzPAtcB7+j/r8HqxAnKSpkGLABeA2xL+hD4ZH5MwHeAdYHNgAnAYQARsS9wHwuvyr7XZrzJwJnAasCpA8Rvx+7A9sBOwFeA40gfchOALYF9Ks99FbAmMI50NXGcpEbT1NHAqsCrgTcB+wEfr7x2R9IH+lrAR4FPAzPyz75afs7T+XWrAXsAB0jas+l43wBsAuwK/IekzXL5F/OxvgsYA3wC+IeklYCLgdNy7H2An2hhn8zxwD9HxCr5572sn9/TVkBzP9GVLExGuwBXAVc3lV0TEc8D3wU2BrYhvVfjgP9oDpJPCH4FnAisAfwCeF/T015F+l2PA/YH/kfS6hFxHOlv4nv59/qeymtuJ13h2QjgBGVD8WtJj+evX0taG3gn8IWIeDoiHgH+E9gbICLmRMTFEfFcRMwDfkT68O7EjIj4dUS8RPog7jd+m74bEU9GxK3ALcBFEXF3RDwBnE9KelX/nn+eK4DfAh/KV2wfBg6OiPkRcS/wQ2DfyusejIijI2JBRDzT6kAi4vKImB0RL0XEzaQP5+bf1+ER8UxE3ATcxMIP3U8Ch0TEnZHcFBGPAu8G7o2IE3Ls64GzgA/m170AbC5pTEQ8lh9vZTVgflNZ9WrpjaQEdVVT2RWSBHwK+NeI+HtEzAe+Tev3aSdgWeCoiHghIs4GZjY95wXgG/nx3wFPkZL24szPP4ONACOuDdxqYc+IuKRxR9IOwHLAQ+kzCEgnP/fnx9cCjiJ9UK2SH3usw2O4v3J7/cXFb9PDldvPtLj/qsr9xyLi6cr9v5CuDtcEls/3q4+N6+e4W5K0I3Ak6UpmeWA0cEbT0/5auf0PYOV8ewLw5xbVrg/s2GhGzJYFTs63PwAcAhwp6WbgoIiY0aKex0jvYdWVwPGSVicllo9ExFOS1sllbwB+DIwFXgFcV3mfBLRqil0XeCD6rmbd/Lt7NCIWVO5Xfw/9WQV4fIDnWE34CspKuB94DlgzIlbLX2MiotF89B0ggK0jYgypaUuV1zcvqf806YMMSP0qpA+3quYPrsXFL2313GTWsB7wIPA30ln9+k2PPdDPcbe6D6kZ7lxgQkSsSuqnUovntXI/sGE/5VdUfj+r5eavAwAi4k8RMZnU/PdrYHo/9d9MaqJb+ANE3E36+acC90XEU/mhGblsZeAa0u/nGWCLyjGsGhGtkspDwDhVMhkp+barv20aNiNdcdoI4ARlHYuIh4CLgB9KGiNpmTzIoNEstQqp+eVxSeOALzdV8TCpz6bh/4AV8mCB5Uhn9qM7iN8Nh0taXtIbSc1nZ0TEi6QP9iMkrSJpfVKf0OKGtD8MjG8MwshWAf6eh3HvAPzTII7rZ8A3JW2kZGtJrwR+A2wsaV9Jy+Wv10naLP8cH5G0akS8ADwJvNhP/TOB1fL7WHVV/lmvqpRdnctm5ebIl4CfAv+Zr6qRNE7Sbi3izMjH8C+SlpU0GdhhEL+H5r+pxgjE7Ul9cTYCOEFZKfuRmqNuIzUDnQk0hvMeThrJ9QSpv+bsptd+Bzgk92n9W+73+Qzpw/YB0hXVQJMyFxe/tL/mGA+SOuM/HRF35Mc+Szreu0kf0KcBP19MXZeRRr39VdLfctlngG9Imk8aQNDf1UwrP8rPv4iUaI4HVsz9Pe8g9fc8mH+G77Iw8e8L3Ks0KvLTpKvcReSBDie2ePwK0tVXdU7XVbmsOrz8q8Ac4Joc6xJa9BvlOO8nDX54PMf7DelKuR3Hk/rUHpf061z2XuDy4Z4WYe2TNyw0a5+kNwOnRMT4YT6UYaM0v+kqYNv+Bnp0Ke61wLERcUIHr98/Im4pe2TWLR4kYWaDkkdibtrtOLmJ9k5S39VHgK2BC4ZaX0TsWOjQrEecoMysrjYhNVeuTBqZ+MHc32hLCTfxmZlZLXmQhJmZ1VLtm/jWXHPNmDhx4nAfhpmZdcl11133t4honutY/wQ1ceJEZs2aNdyHYWZmXSLpL63K3cRnZma15ARlZma15ARlZma15ARlZma15ARlZma15ARlZma1VPth5v2ZeNBvB/2ae4/cowtHYmZm3eArKDMzqyUnKDMzq6W2EpSk1SSdKekOSbdLer2kNSRdLOmu/H31yvMPljRH0p3V3TIlbS9pdn7sqKbtnM3MzF7W7hXUfwEXRMSmwGuB24GDgEsjYiPg0nwfSZuTdu3cAtgd+ImkUbmeY4CpwEb5a/dCP4eZmS1hBhwkIWkMsAvwMXh5K+bnJU0G3pyfNg24nLSd82Tg9Ih4DrhH0hxgB0n3AmMiYkau9yRgT+D8Yj9NYR6IYWY2fNq5gno1MA84QdINkn4maSVg7cbmYfn7Wvn544D7K6+fm8vG5dvN5YuQNFXSLEmz5s2bN6gfyMzMlgztJKhlge2AYyJiW+BpcnNeP1r1K8ViyhctjDguIiZFxKSxYxdZgd3MzJYC7SSoucDciLg23z+TlLAelrQOQP7+SOX5EyqvHw88mMvHtyg3MzNbxIAJKiL+CtwvaZNctCtwG3AuMCWXTQHOybfPBfaWNFrSBqTBEDNzM+B8STvl0Xv7VV5jZmbWR7srSXwWOFXS8sDdwMdJyW26pP2B+4C9ACLiVknTSUlsAXBgRLyY6zkAOBFYkTQ4orYDJMzMbHi1laAi4kZgUouHdu3n+UcAR7QonwVsOYjjMzOzpZRXkjAzs1pygjIzs1pygjIzs1pygjIzs1pygjIzs1pygjIzs1oasTvqLim8IK2ZWWu+gjIzs1pygjIzs1pyE99SYrBNiW5GNLPh5isoMzOrJScoMzOrJScoMzOrJScoMzOrJScoMzOrpbYSlKR7Jc2WdKOkWblsDUkXS7orf1+98vyDJc2RdKek3Srl2+d65kg6Ku+sa2ZmtojBDDN/S0T8rXL/IODSiDhS0kH5/lclbQ7sDWwBrAtcImnjvKvuMcBU4Brgd8DueFfdJYaHsptZSZ008U0GpuXb04A9K+WnR8RzEXEPMAfYQdI6wJiImBERAZxUeY2ZmVkf7SaoAC6SdJ2kqbls7Yh4CCB/XyuXjwPur7x2bi4bl283ly9C0lRJsyTNmjdvXpuHaGZmS5J2m/h2jogHJa0FXCzpjsU8t1W/UiymfNHCiOOA4wAmTZrU8jlmZrZka+sKKiIezN8fAX4F7AA8nJvtyN8fyU+fC0yovHw88GAuH9+i3MzMbBEDJihJK0lapXEbeAdwC3AuMCU/bQpwTr59LrC3pNGSNgA2AmbmZsD5knbKo/f2q7zGzMysj3aa+NYGfpVHhC8LnBYRF0j6EzBd0v7AfcBeABFxq6TpwG3AAuDAPIIP4ADgRGBF0ug9j+CzQfH+WWZLjwETVETcDby2RfmjwK79vOYI4IgW5bOALQd/mGZmtrTxShJmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLbScoSaMk3SDpN/n+GpIulnRX/r565bkHS5oj6U5Ju1XKt5c0Oz92VN5Z18zMbBGDuYL6PHB75f5BwKURsRFwab6PpM2BvYEtgN2Bn0galV9zDDCVtA38RvlxMzOzRbSVoCSNB/YAflYpngxMy7enAXtWyk+PiOci4h5gDrCDpHWAMRExIyICOKnyGjMzsz7avYL6MfAV4KVK2doR8RBA/r5WLh8H3F953txcNi7fbi5fhKSpkmZJmjVv3rw2D9HMzJYkAyYoSe8GHomI69qss1W/UiymfNHCiOMiYlJETBo7dmybYc3MbEmybBvP2Rl4r6R3ASsAYySdAjwsaZ2IeCg33z2Snz8XmFB5/XjgwVw+vkW5mZnZIga8goqIgyNifERMJA1+uCwiPgqcC0zJT5sCnJNvnwvsLWm0pA1IgyFm5mbA+ZJ2yqP39qu8xszMrI92rqD6cyQwXdL+wH3AXgARcauk6cBtwALgwIh4Mb/mAOBEYEXg/PxlZma2iEElqIi4HLg8334U2LWf5x0BHNGifBaw5WAP0szMlj5eScLMzGrJCcrMzGrJCcrMzGrJCcrMzGqpk1F8ZkukiQf9dtCvuffIPbpwJGZLN19BmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLQ2YoCStIGmmpJsk3Srp8Fy+hqSLJd2Vv69eec3BkuZIulPSbpXy7SXNzo8dlXfWNTMzW0Q7V1DPAW+NiNcC2wC7S9oJOAi4NCI2Ai7N95G0OWlr+C2A3YGfSBqV6zoGmEraBn6j/LiZmdkiBkxQkTyV7y6XvwKYDEzL5dOAPfPtycDpEfFcRNwDzAF2kLQOMCYiZkREACdVXmNmZtZHW6uZ5yug64DXAP8TEddKWjsiHgKIiIckrZWfPg64pvLyubnshXy7ubxVvKmkKy3WW2+99n8asxHCK6abDaytQRIR8WJEbAOMJ10NbbmYp7fqV4rFlLeKd1xETIqISWPHjm3nEM3MbAkzqFF8EfE4cDmp7+jh3GxH/v5IftpcYELlZeOBB3P5+BblZmZmi2hnFN9YSavl2ysCbwPuAM4FpuSnTQHOybfPBfaWNFrSBqTBEDNzc+B8STvl0Xv7VV5jZmbWRzt9UOsA03I/1DLA9Ij4jaQZwHRJ+wP3AXsBRMStkqYDtwELgAMj4sVc1wHAicCKwPn5y8zMbBEDJqiIuBnYtkX5o8Cu/bzmCOCIFuWzgMX1X5mZmQFeScLMzGrKCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGqprR11zWxkGuzOvd611+rEV1BmZlZLTlBmZlZL7eyoO0HS7yXdLulWSZ/P5WtIuljSXfn76pXXHCxpjqQ7Je1WKd9e0uz82FF5Z10zM7NFtNMHtQD4UkRcL2kV4DpJFwMfAy6NiCMlHQQcBHxV0ubA3sAWwLrAJZI2zrvqHgNMBa4BfgfsjnfVNRvR3M9l3TLgFVREPBQR1+fb84HbgXHAZGBafto0YM98ezJwekQ8FxH3AHOAHSStA4yJiBkREcBJldeYmZn1Mag+KEkTSdu/XwusHREPQUpiwFr5aeOA+ysvm5vLxuXbzeWt4kyVNEvSrHnz5g3mEM3MbAnRdoKStDJwFvCFiHhycU9tURaLKV+0MOK4iJgUEZPGjh3b7iGamdkSpK0EJWk5UnI6NSLOzsUP52Y78vdHcvlcYELl5eOBB3P5+BblZmZmi2hnFJ+A44HbI+JHlYfOBabk21OAcyrle0saLWkDYCNgZm4GnC9pp1znfpXXmJmZ9dHOKL6dgX2B2ZJuzGVfA44EpkvaH7gP2AsgIm6VNB24jTQC8MA8gg/gAOBEYEXS6D2P4DOzAQ12pCAMfrRgL2LY4AyYoCLialr3HwHs2s9rjgCOaFE+C9hyMAdoZmZLJ68kYWZmteQEZWZmteQEZWZmteTtNszMesQDMQbHV1BmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZLTlBmZlZL7eyo+3NJj0i6pVK2hqSLJd2Vv69eeexgSXMk3Slpt0r59pJm58eOyrvqmpmZtdTOFdSJwO5NZQcBl0bERsCl+T6SNgf2BrbIr/mJpFH5NccAU0lbwG/Uok4zM7OXDZigIuJK4O9NxZOBafn2NGDPSvnpEfFcRNwDzAF2kLQOMCYiZkREACdVXmNmZraIoW63sXZEPAQQEQ9JWiuXjwOuqTxvbi57Id9uLm9J0lTS1RbrrbfeEA/RzGzpNNhtPeq6pUfpQRKt+pViMeUtRcRxETEpIiaNHTu22MGZmdnIMdQE9XButiN/fySXzwUmVJ43Hngwl49vUW5mZtbSUJv4zgWmAEfm7+dUyk+T9CNgXdJgiJkR8aKk+ZJ2Aq4F9gOO7ujIzcxs2PSiGXHABCXpF8CbgTUlzQUOJSWm6ZL2B+4D9gKIiFslTQduAxYAB0bEi7mqA0gjAlcEzs9fZmZmLQ2YoCJin34e2rWf5x8BHNGifBaw5aCOzszMllpeScLMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGrJCcrMzGqp5wlK0u6S7pQ0R9JBvY5vZmYjQ08TlKRRwP8A7wQ2B/aRtHkvj8HMzEaGXl9B7QDMiYi7I+J54HRgco+PwczMRgBFRO+CSR8Edo+IT+b7+wI7RsS/ND1vKjA1390EuHMQYdYE/lbgcIc7Rq/iOEa9YvQqjmPUK0av4tQ1xvoRMba5cNkyx9M2tShbJENGxHHAcUMKIM2KiElDeW2dYvQqjmPUK0av4jhGvWL0Ks5Ii9HrJr65wITK/fHAgz0+BjMzGwF6naD+BGwkaQNJywN7A+f2+BjMzGwE6GkTX0QskPQvwIXAKODnEXFr4TBDahqsYYxexXGMesXoVRzHqFeMXsUZUTF6OkjCzMysXV5JwszMaskJyszMaskJyszMaskJyqyGJK093McwFHk5s27HWKHbMYZTqfde0jKS/l+JuobLEjFIQtJY4FPARCojEyPiEwVjvAL4ErBeRHxK0kbAJhHxm1IxcpwVc4zBrJ5RK5IEfAR4dUR8Q9J6wKsiYmbhOFsBm+a7t0fELSXrr8TpyXsiaVXgA8A/AZtFxLguxBgHrE/f/5MrC9Z/D3AmcEJE3Faq3qYYc4CHgauAK4E/RMQTXYjz/1j0M+Wk0nFyrK6895JmRMTrS9Q1QJyu/M8vKQnqj6Q/1uuAFxvlEXFWwRi/zPXvFxFb5g+tGRGxTcEY7wF+ACwfERtI2gb4RkS8t1SMHGcS8HUWflAJiIjYulD9xwAvAW+NiM0krQ5cFBGvK1T/qsA5pEnfN5OOfyvgPmByRDxZIk6O1dX3JP8dvZf0wbQdsAqwJ3BlRLxUIkYl1neBDwO3sfD/JEr+fUlahTS/8eOkFpqfA6eXfE9ynPWANwI7A+8CHi/8v3gysCFwI31/V58rGKPr772kw0n/I2dHFz/su/Y/HxEj/gu4sQcxZuXvN1TKbioc4zpg1aYYN3fhZ7mT9I+xASlJrU9aC6tU/dd383cFHEVKGstUypYBvgccPVLeE+BU4H7geODtpLmB95R+v5ve99Hdqr9FvF2AB4CngWnAawrVOx7YBzgWmAH8Fji48LHfTj6B79LvpifvPTCflDieB57M95/sQpyu/M/3ei2+bvmNpHdFxO+6GOP5fMYTAJI2BJ4rHGNBRDyRrpa7al5EdHMFjxdyX0TjdzWW9E9SytuAraNylhkRL0n6GjC7YBzo7nuyJfAY6cPwjoh4UVI3mzTuBpaj/N/ty/L7vgfpCmoi8EPSh/Ebgd8BGxcIcx9pVZpvR8SnC9TXyi3Aq4CHulR/T977iFildJ396Mr//JKSoD4PfE3S86QzhUaT1ZiCMQ4FLgAmSDqV1LTwsYL1A9wi6Z+AUbmP63PAHwvHADhU0s+AS6l8WEXE2YXqPwr4FbCWpCOADwKHFKob4PmIWNBcGGmlktIfvl17TyLitZI2JTXxXCLpEWAVSa+KiL+WiAEg6WjSB8c/gBslNb/vxZqtgLuA3wPfj4jq7+lMSbsUirEt8Abgn/Kmp3cBV0TE8Z1WLOk80u9qFeA2STPp+7sq0hzaq/ceIDe3bQS8PLgkCvY7Zl35n18i+qB6RdIrgZ1ICfCaiCi6bH0eiPF14B05xoXANyPi2cJxTiENLriVhWc5EWUHlWwK7Er6OS6NiNsL1n0HqYmn+bJGwCkRsVnBWD15T3KsSaQPrA8CcyOiyAgsSVMW93hETCsRJ8daOSKeKlXf4uKQktQbgY+S/n4nFqj3TYt7PCKu6DRGP3G79d5/knQCP57Un7YTqe/8rSXqb4pV/H9+iUhQlREkG0TENyVNANaJgqPGJG3XovgJ4C+tzubrTNLsiNiqyzFWJw1iqI6Aur5Q3ZfTYpuWSpy3lIgzXPLf8y7d+jDspjwEfH9gC/qesZc8+ZkFjCZdyV5NGlTwl1L15xjfjYivDlRWWun3XtJs4HWkE+ptchI5PCI+XKL+SpwNSYn1OUlvBrYGToqIxzupd0lp4vsJeQQJ8E3gKdLW8kVGjVVibMfCUWNb5tuvlPTpiLio0wCV5oWqJ4BZwP8WPGu/RtLm0b1hwN8kNX/+mYU/T5Den45FxJtL1NMOSRsD/8aiw407/lkkHTXAU4omqPxh1d/f17ci4tECYU4G7gB2A75BOnEsdvWcvTMi5hWus9nbgeZk9M4WZUPSw/f+2Yh4VhKSRkfEHZI2KVR31VnAJEmvAX4GnAecRhphOWRLSoLaMSK2k3QDQEQ8prSdR0n3AvtHXn1d0ubAl0kJ8Wyg4wRF6sQeC/wi3/8wab7HxsBPgX0LxIDUNDIlz1l5jsLDzIEPARtGxPOF6utD0kdJV/8nN5V/Cng6Ik4rGO4M0mixn1GZwlDIp0md8dNJ+6J1e3TM+aSfofH72TvHfAI4EXhPgRiviYi9JE2OiGmSTiM1i5b0vKQfkUYJQvow/0YUmAsl6QDgM8CrJd1ceWgVyvYH9+q9nytpNeDXwMWSHqM7e/C9lPuA3w/8V0Qc3fg87sSSkqC6PWoMYNOobA0SEbdJ2jYi7i44wmvbiKh2JJ8n6cqI2EVSyW1Jdi9YVyu3AKsBj3Sp/i+x8MOp6pekDvqSCWpBRBxTsL6qdYC9SCciC0jHf1ZEPNaleDtHxM6V+7Ml/SEids5Jv4QX8vfHJW0J/JV09VnSz0l/Yx/K9/cFTgDeX6Du00iJ/DvAQZXy+RHx9wL1N/TkvY+I9+Wbh0n6PWnKxAUlY2QvSNoH2I+FJzrLdVrpkrLUUWMEydp5BMnVwLcLx7hT0jGS3pS/fgL8n6TRLPyn7NTYPAEReHky4pr5brGrkYj4S26zf4aU1BtfpXwHuEHShZLObXwVrH9URMxvLow0GbTjf4om50n6jKR1JK3R+CpRcUQ8GhHH5j6zj5GS+q2SSl0pN1tZ0o6NO5J2AFbOd0v1ox6X+x8PIW1Gehvw3UJ1N2wYEYdGxN3563Dg1SUqjognIuLeiNiHtAP4C6T/jZWr/5sF4vTsvZf0Bkkfz/1aM4DiK5SQphW8HjgiIu6RtAFwSqeVLhGDJKDPCBKAy0qOGsv1r0i69H8D6XL8alK/1LPAK0qMXJL0LlJz0p9zjA1yzMuBT0XEjzuNkeO8lzQ/ZV3SVc76pKWCtihU/63A/5LmJFXnKpXq+L0dmBQRTzeVrwL8KSI2bf3KIcW6p0VxRESRD8QcYzvSqMS3kyYG/7Ab/YOSXke6+liZ9Pf1JPBJ0mjOPSJiegd1f7FVcf4eEfGjodbdItYM4MsRcXW+vzPwgyi4pI/SxqqHkZrYqyNdSzWDN+J09b2XdCgwibQs28aS1gXOaLqSrq0lKUFtR0oeQVqbq8iIsV7LV2Sbkv657+jScOabSAMWLomIbSW9BdgnIqYWqv+KiFjscN0O6/830snIARFxby6bSBoYc3lEfL9bsUtSWobm3aRBBKcDF/RiRKjSUlHqdIRVU52H5pubkAYnNa6Y30MaZffJgrFeC5xEaq6CNOF1SkTc3P+rBh1jDqlvu8TAkVb19+S9l3Qjad7Y9RGxbS67uQuJdiNSy8nm9B292dGJ3BKRoCT9B6k99yzSB/uepLOEbxWMsTPpjKp5oc1iZ9I5TtcXqJQ0KyIm5US1baRVGGZGxA6F6v8RafDFufSd5FjspEHSp4GDSVcDQVpO58hS/UWS3hoRl+VO30VEgUnNkl4iDYx5plFt4yHKro340Yg4pZ+rHApf3VwEfKDRBJuvas+IiOL9npLGQGralfSFUi0Mue7fA2/v1glDD9/7mRGxg6Tr80CylUjzoEonqKtJixn8J+mk5OOk/HLoYl84gCVlkMQ+pA/aZwEkHQlcDxRLUKQ1s/6VpgVpS1I/C1SSzhZLelxpouOVwKlKs9hL/iNum7/vVCkrNswcICKOBY7NP4cqH4ivi4g/FQjxJuAyWo9sC9LIzU5tUKCOdqyUv/di2Zv16Ntf+jzlB0kAL/c5NnwR+HHB6u8GLpf0W/qeZJVK5r1676dL+l9gtTzK9ROkEcGlrRgRl0pS7t8+TNJVpKQ1ZEtKgrqXdFnZaA4bTerHKemJiDi/cJ3NJgGbR/cvayeTztz+lTRPZVXSnJUioocTZSPiKUmbS9qbdKLyBOn32Gm9h+bvH29+TNIHOq0/WzEi7sh1jo6Ilz8IJe0EFJl8GhH/m78fXqK+AZwMzJT0K1Iifx9podhuKz1M+778tXz+Kq0n7z0puV5C6m/cBPiPiLi4UN1Vz0paBrgr9989AKzVaaVLShPfr0nt3o1f/NtIgxgegTJrjeWrslGkM+duNVudAXwuIrq1QGVjMc8LI+JtXYzxH63KI6JYEpS0Pikh7UO6+lufNHDi3lIxFhP7vojoeERXo9ml+Xar+x3GWeyk0BL/H03xtiMtQQSp/6nj+TBtxCzynrSodxVSk1vR5Zt6+N5/izTf7XrSAJkLu3ECnAfg3E4ajfhNYAxpPcZrOql3SbmCupC08OlLpKax33chRmN4bvXsvGizFWlIedcWqMx1vSjpH5JWjS5s8pZVR9etwMLO4CKU9v9aldS5/MGIuEvSPb1ITo1D6EI9rdYVLOW6yu3D6bDZZSD5pK34ICVJ82k9HULAioVjbUm6Glwj3/8baS+4UvMRe/LeR8Qhkv6dtJbkx4H/ljQdOD4iirUyNZrVUwvfoq0OQzWiE5SkZUnznT5BuiRehrT+2wnA1yKi1PykXjVbHdaDGJCaQmdLuphKMil1Jh0RP6zel/QDFo7qKmEeafHLtUkrb9xF2XlcAykVK/q5XTJGn8Vg82CCXjS5FRe92zoC4DjgixHxewCl9eV+CpTaQr0n7z2kyz9JfyVNml4ArE5aXf7iiPhKiRiSXk/qp18ZWC+PtPzniPhMJ/WO6AQFfJ/U8btBpZN8DGkzu+8DXygZTNIeLLoIZsm+m14tDvrb/NUrr6DQREqAiJishVtkH660/tdqknaIQgsEq/W6dZDObtcuEQMYn5vfVLndiNGNyZTQ20Q+kq3USE4AEXF5HgFXSk/ee0mfA6YAfyMt1/XliHih0V8EFElQpAEqu5FPRCPiJhXYXmWkJ6h3AxtX21TzkNMDSAtWfqFUIEnHkj5o30J6oz8IFFstPcfYCTga2IzUMTuKtLZcyX2tim6v0ErTh/so0lVOsUQOacY/qU3955LWJi0Z82NJEyJiQoEQ7y5Qx0C+XLk9q+mx5vvWW3fnprHGeo8fBVpN2h6qXr33awLvj6bV3vPUkqJ/4xFxv/ou+9bxaOcRPUhC0v9FRMsdOhf32BBj3RwRW1e+rwycHRHvKBhjFqlD8wxSX9d+wEYR8bVSMXKcrq5qnQcwNCwAHu7WfJJWsZv/GetO0l4RccZAZR3UX+27eQVp40JYOOem6AnQkkBpuabDSRuTijQl47AoOLl5SSLpTOBHwH+Tppd8jjRoae9O6h3pV1C3SdovmiayKi18eUfhWI0h7P9QWi7kUbowlyEi5kgaFREvAifkAQGldWVVay1co655nbwxkohCi21q4HX9Oh5UMkCHfOkP9YNJJyUDlQ1Jj/tulhQbkvqzlyF9Tu5KGhBVeoJrr7bY6bZPA/9Fap6cS9rd4cBOKx3pCepA4GxJnyCNVArScPMVSfMvSjpPadn675NGKAXlJ7z9Q2mbkBslfQ94iIWTLEvq1qrWjfeg1SikoFw/1OuB+0nbklzbT7yO9OJDXdI7SfvljGsaCj6GshOnbfBOJe0Ddgvld0ao6tUWO12Tp678OCI+UrruEZ2gIuIBYEdJbyUNXhBwfkRcWjJO7lC8NF/enyXpN8AKXRimvS/pjO1fSJNoJ5AGApS2sqQdI+JaoNiq1hHRq9nxryItrrkPaZvs3wK/KDgEeBGS1qLv4Jj7ClT7IOlM+b30HQo+n/T+2/CZFxHn9SBOr7bY6Zo8dWWspOWj8B5wI7oPqpckzYiCqyUPJ7Ve1Xp/0tYIHa1qXYnxXhbu2XR5RPym0zr7iTOalKi+T9q07ujC9Xd75fdRpK2xi5992tBJ2pX0d3UpfecklljiqhrndmC3xgmP0pYeF0TE5pJuiLzAa90pLae0HWkUX3XqSkdLQ43oK6geuygvcXN2N2ZiQ+8WpM2T6rZS61WtSySnI0lNrafmos9L2jkiDu607kqM0cAepA+RiaQ9wYp+eGTfJHX69ln5vVTl+ezzld04+7SOfJy0q8ByVLbboPzf2JeAqyX12WInD2kfSfPVHsxfy1BwzUdfQbUpd5qvRGoCe5YudJZLuoMWC9J2OqquRZxVSasJFN8yO9d/M7BNRLyU748CbohyKzRPA7YkDfY4PSJuKVFvP7G6uvJ7jtGVs08bOkmzI2KrHsXq+hY7I5WvoNo0UKe5pC0K9IH0YkFa6O6W2Q2rAY1Re6su5nlDsS/pg3xj4HOVuRfdGGHX7ZXfoUtnn9aRayRtHl3YOLKF7Vm4xc7WecRr6R0MuiqvSrNXozUmD9M/PSJ266heX0GVoQ4WeFRaXBNSwujqgrQ53o0Rsc1AZUOo979Jo5EmAEeSdgIW6Urt4Ig4vZP6h0NuamlcMTdWfj+19FVtjtWVhUlt8HLf0IakybnPQdl9mipxWm6xE4UX8O22fj5TOu5D8xVUOZ0Mdf5h0/1uLkgL8IykN0TfLbOfGeA17biLtMzUOqR5EPcDNwFfjYi/Fqi/56LvtvJd6RNQ9xcmtcErvsFiP3q1xU63vShpvcpgj/UpsKyWr6AK6eQKqtfU5S2z8x/n3vlrBdKE4NMj4q4S9feS0o663yXtbSO60/f4R+Dr0Xdh0m9HRKmFSa2m1IMtdnpB0u6kBXYb64nuAkyNiAs7qtcJqowSCUrSt4HvNbXjfikiDilwiNU4G0TEPeq7ZfYGEVFyrbFGrG1JfV5bR8So0vV3m6Q5wHsioth2IS1i3BQRrx2ozJY8SlvLb0Na17MrW+z0iqQ1SSNeRdpW/m+d1ukmvnJKDBF+Z1TW3YuIxyS9CyiaoICzgO2i75bZZ5I6azsmaTlSE8nepCViriCtazYSPdzN5JR1e2FSq6/DhvsAChpNGhi1LLB5HuxxZScVOkG1SdJZpCuB8xvDp6siYqcCYUapsv2zpBVJb3oRkjYlrbixam66ahhDZZWEDupvrO6wB+mM8HTSZf7Ti31hvc2S9Evg13RvwuYnSAn8bBYuTFps0zerr4i4Qmk1/tflopkR8chwHtNQSPouaZmmW+k7b6yjBOUmvjZJehvpQ2Mn0iKeJ0ZE0QVpJX2FtOzNCaQ39xPAuRHxvUL1Twb2zDGqC67OJ/URdbQwbW6uOA04KwotDDvcJJ3Qojgi4hM9Pxhb4kj6EGkVlMtJJydvJO3ZdOZwHtdgSbqT1Iz/3IBPHky9TlCDkye57gN8nTRK7afAKVFo997c2fg20h/rRZ12MvYT4/URMaN0vTY0kjYmLUw6kb4riJQevWk1kyeAv71x1SRpLGnVkhHV/yjpfNI8qKJTJNzENwiSXknqH9gXuIG0lM8bSDtWvrlEjIi4ALign/il1gN8X16I8pkc67XAFyLilAJ1L1GaVhlveAKYFRHnFApzBnAsaSPMjjd5sxFlmaYmvUdJE7ZHmn+QdmFoXruwo/lcTlBtknQ2aTmSk0mjuhrDQn+ptNFgL3TcT5S9IyK+Iul9pL1b9gJ+DzhBLWoF0vve2JvpA6R29v0lvSUivlAgxoKIOKZAPTbyXCDpQvput/G7YTyeoTqXvt0GRbiJr02S3hoRlw3zMRSZayXp1ojYQtJPSf1FF3hYc2uSLiMl9AX5/rKkSchvB2ZHxOYd1N3Y4PFzpJXSf0Xfs88loh/PFi8vQv3yzr0R8athPqTa8BXUAKqj3ZpGvgHll9/vkfPywrTPkFZOHsvCHYOtr3GkRYIbC+muBKybVyHvtEO4eYPHL9N39n3RVeytniLiLNLUjxFH0vSI+JCk2bRYOaLTpaGcoAa2uO3Pu7H8/uIU2Tk2Ig7Kw0KfzB+0TwOTS9S9BPoeqW39chauK/jtvEbfJZ1UHHmDxzyS64I8YfrfSSubf7Ojo7Zay7sjtGq+6saCx930+fz93d2o3E18NZOXCdooIi7J86CWjYj5+bEtO9laotFM2epKEEbs1WDXSVoH2IH04TEzIh4sXP/NEbG1pDcA3yatzfi1iNixZByz4TLUAV6+ghqApI9GxCmSvtjq8Si4Z4+kTwFTSYuGbgiMJ43u2jXH6nTfozcBl9H6qrDXV4O1JmnTiLijstL8/fn7qyS9qvAK842Re3sAx0bEOZIOK1i/2XAb0gAvJ6iBrZS/92KfngNJZ+rXAkTEXZLWKlV5RByav3uVgoF9kXSyUF1pvtrcUHKO0gN508K3Ad/NG9iNxKHGZv0ZUlOdm/hqRNK1EbFjYx+VPGLs+i7sQTOaNFx6In0nhn6jZJwlQX/9QyWvoCS9grR24ex8UrIOsFVEXFQqhtlwGuoIZF9BtUnSCsD+pLXsXr5cLbzkzRWSvgasmNe1+wxwXsH6G84hjUq7jsqwZmvpkIiYnvuH3k66ojoGKNY/FBH/oNK8mufYjejtF8yaDGmAlxNU+04G7gB2A75B2l219CrXB5GS4Gzgn0kT9n5WOAbA+Ijo1YZsI537h8zasLgBXqTVdwZfp5v42lNpdmuMuFoOuHAkrpcm6Tjg6IiYPdzHUneSfgM8QOof2p40d2ymJzWbLVQd4BURG0raiHRCt2sn9bojtn2NxWAfV9qie1VSH04xkt4t6QZJf5f0pKT5kp4c+JVt1z9b0s2k9QOvl3SnpJsr5baoDwEXArvnjSTXIE2oNbOFDiSthvEkpAFepF2oO+ImvvYdp7TD7SGkNadWBv69cIwfA+8ndZZ349K2rcl0klaPiMe6EH/Ecf+QWVuei4jnpdTVlAd4dfwZ5gQ1gKb5T43h2f+Tv69EWfcDt3QpORERf2nzqZeSRquZmbWjKwO8nKAG1pj/tAlp18vGir3vocPdIlv4CvA7SVfQd9HQYpOB21RkSSUzW2p0ZYCXB0m0SdJFwAcqyw6tApxRcjRcjvEU6U1+eVv5iDi8VIw2j6PIqulmtnTIa1M+GxEv5vujgNG5iXzIfAXVvvWA5yv3n6fwIAnSCJh3FK7TzKzbLiWNdG3sqLsiaVua/9dJpU5Q7TsZmCnpV6TOv/cB0wrHuETSO2qwgoCb+MxsMFaobvceEU/lFVI64ia+QcgLh74x370yIm4oXP980sCL50jD2ruy9L6krUi7xALc3rwIraQ1vFmembVL0h+AzzaWAJO0PfDfQ1nBvE+9TlBLD0mrkpY5mgDcTEqAWwH3AZMjoticKzNbekh6HXA60NiKZh3gwxFxXUf1OkHVh6RdWpVHRJHRgpKOIvWdfSUiXsplywBHAitGxGdLxDGzpU9eXWcT0onvHRHxwgAvGbhOJ6j6kFSdN7ACaeuN60otpyTpNmDriFjQVL4saXLwZiXimNnSoduboHqQRI1ERJ+NBCVNIG05Xsrzzckpx10gyauam9lgdXUTVCeoepsLbFmwvhUkbcuio/QEjC4Yx8yWAhFxaO4mOD8ippeu3018NSLpaBauX7UMsA1wb0R8tFD9l7OY9bEi4i0l4pjZ0kXSlRHRsg+9o3qdoOpD0pTK3QWk5PSH4ToeM7N25N2mnwF+CTzdKO90uooT1FJE0kdJ7/nJTeWfAp6OiNOG58jMbCSTdA8tWmci4tUd1esENfwkzaZ101tjou7WheLcAOxS2eWyUT4G+H1EbF8ijpktXfIOup8h7TUXwFWkDQuf6aReD5Koh7b2aSpgVHNyAoiIJ/McBjOzoZhG2qzwqHx/n1z2oU4qdYKqgeo+TZLWJm3rAWlr8UcKhlpO0koR8XS1MK/MvnzBOGa2dNkkIl5buf97STd1Wqm3fK8RSR8CZgJ7kc48rpX0wYIhjgfOlDSxEnMiaYmS4wvGMbOlyw2SdmrckbQj0PEAL/dB1Ug+43h746pJ0ljgkqYzk05jfBo4mLRlfZBG3BwZEceUimFmSxdJt5OWObovF60H3E7a127I/ehOUDUiaXZEbFW5vwxwU7WsYKyVSe9/YwPG10XEn0rHMbMln6T1F/d4tRtjMNwHVS/nS7oQ+EW+/2HS1snF5f1aNpe0N6lD8wlgUjdimdmSbagJaCBOUPXyV9J279uQhpgfFxG/Khkgn+nsk78WAOsDkyLi3pJxzMw65UES9bIKcBBpFfM/A38sWbmkP5KuyJYDPpjnPc13cjKzOnKCqpGIODwitgAOBNYFrpB0ScEQ80hJcG1gbCNswfrNzIpxgqqnR0jNfY8Ca5WqNCImk3bQvR44PC9PsrqkHUrFMDMrxaP4akTSAaSBEWOBM4FfRsRtXYy3do63NzAhIiZ0K5aZ2WA5QdWIpCOB0yPixmGIvX63RuKYmQ2FE9RSRNK5i3s8It7bq2MxMxuIh5kvXV4P3E+aZ3Uti+6sa2ZWG76CWopIGgW8nTQHamvgt8AvIuLWYT0wM7MWPIpvKRIRL0bEBRExBdgJmANcLumzw3xoZmaLcBPfUkbSaGAP0lXURNL+LWcP5zGZmbXiJr6liKRpwJbA+aTRgrcM8yGZmfXLCWopIukl0vYa0HcFicbW8mN6f1RmZq05QZmZWS15kISZmdWSE5SZmdWSE5SZmdWSE5SZmdXS/wcXZIqHx8QbdQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importances based on 'weight'\n",
    "importances_weight = booster.get_score(importance_type='weight')\n",
    "\n",
    "# Convert the importance dictionary to a pandas Series\n",
    "xgb_importances_weight = pd.Series(importances_weight)\n",
    "\n",
    "# Sort the values of the series in decending order\n",
    "xgb_importances_weight = xgb_importances_weight.sort_values(ascending=False)\n",
    "\n",
    "# Create the figure and the axis\n",
    "fig_weight, ax_weight = plt.subplots()\n",
    "\n",
    "# Create a bar plot and set the axis as `ax_weight`\n",
    "xgb_importances_weight.plot.bar(ax=ax_weight)\n",
    "\n",
    "# Set the title for the plot\n",
    "ax_weight.set_title('Feature Importances (Weight)')\n",
    "\n",
    "# Adjust the spacing between the plot elements\n",
    "fig_weight.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the `gain` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importances based on 'gain'\n",
    "importances_gain = booster.get_score(importance_type='gain')\n",
    "\n",
    "# Convert the importance dictionary to a pandas Series\n",
    "xgb_importances_gain = pd.Series(importances_gain)\n",
    "\n",
    "# Sort the Series by importance\n",
    "xgb_importances_gain = xgb_importances_gain.sort_values(ascending=False)\n",
    "\n",
    "# Create the figure and the axis\n",
    "fig_gain, ax_gain = plt.subplots()\n",
    "\n",
    "# Create a bar plot and set the axis as `ax_gain`\n",
    "xgb_importances_gain.plot.bar(ax=ax_gain)\n",
    "\n",
    "# Set the title for the plot\n",
    "ax_gain.set_title('Feature Importances (Gain)')\n",
    "\n",
    "# Adjust the spacing between the plot elements\n",
    "fig_gain.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `weight` plot, we can see that, alongside the features we originally had -- High, Low, Open, Volume, and date-related features --, the engineered features are also used significantly, which shows the importance of feature engineering.\n",
    "\n",
    "In the `gain` plot, we see that our engineered `shortEMA` feature also contributed in reducing the model's loss, and that is definitely valuable in improving the model's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are done with the development of this model, it is time to include our findings. In a few questions, we will include some key points about the Microsoft Stocks Project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "1. Would we recommend this model for Microsoft stock price prediction? Why or why not?\n",
    "\n",
    "> *The model had a impressive performance, and has been carefully analyzed and trained. Still, there is till room for improvement, as there can be more powerful models built for this purpose. However, this model has shown very good scores for both validation and test data. That gives us the confidence of saying that this model can have value for the client if used specifically for predicting Microsoft stock prices, which lets us say that we do recommend this model for Microsoft stock price prediction.*\n",
    "\n",
    "2. What is the benefit of using an ensemble of tree-based models like XGBoost over linear regression model for regression tasks?\n",
    "\n",
    "> *Tree-based ensembles are generally better performing and give better predictions. If we are prioritizing the predictive accuracy of the model and making sure it is close to the actual target values, then tree-based modeling definitely outperforms the linear regression, but it might not **always** be the case.*\n",
    "*Also, tree-based modeling does not require significant data cleaning and require much fewer assumptions about the distribution of their target variables. This makes tree-based modeling more convenient to work with.* \n",
    "\n",
    "3. What could you do to improve this model?\n",
    "\n",
    "> *Further feature engieering for generating better predictive signals and using more advanced technical indicators such as Relative Strength Index (RSI) or Bollinger Band can be helpful in improving this model. Also, reconstructing the model with different combinations of hyperparameters can also end up effective to our model performance.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
